#!/bin/bash
# SAMBA startup script for running the main pipeline as a cluster job.
if [[ -d $SAMBA_PATH ]];then
    SPath=${SAMBA_PATH};
elif [[ -d ${SAMBA_APPS_DIR}/SAMBA ]];then
    SPath="${SAMBA_APPS_DIR}/SAMBA";
else
    SPath="$( cd -- "$(dirname "$0")" >/dev/null 2>&1 ; pwd -P )";
fi

# Temporarily turning this off...think I'm not installing things correctly.
#perlbrew switch perl-5.16.3;

#perl -V | tail -20;
local_perl="${SPath}/local/lib/perl5";
# if [[ -d "${local_perl}" ]];then
#     export RADISH_PERL_LIB="${local_perl}:${RADISH_PERL_LIB}";
# fi
# PERL5LIB="${RADISH_PERL_LIB}:${PERL5LIB}"; export PERL5LIB;
PERL5LIB="${local_perl}"; export PERL5LIB;

###############################################################################
# Container-aware pipeline launcher for cluster jobs
#
# When running via samba-pipe, CONTAINER_CMD_PREFIX will be set in the
# environment inside the *login-node* container. We want Slurm/SGE worker
# nodes to also run the pipeline inside the container, so we embed that
# prefix directly into the batch script.
#
# For non-cluster runs (cluster_code==0) we deliberately *do not* use
# CONTAINER_CMD_PREFIX again, because SAMBA_startup itself was already
# launched inside the container.
###############################################################################
if [[ -n "${CONTAINER_CMD_PREFIX:-}" ]]; then
    PIPELINE_LAUNCH="${CONTAINER_CMD_PREFIX} ${SPath}/vbm_pipeline_start.pl"
else
    PIPELINE_LAUNCH="${SPath}/vbm_pipeline_start.pl"
fi

echo ${SPath}/vbm_pipeline_start.pl "$@"
#sleep 2
echo " "
echo " "

cluster_code=$(bash "${SPath}/cluster_test.bash");

if ((! ${cluster_code})); then
    ###########################################################################
    # Non-cluster: run directly (we are already inside the container here).
    ###########################################################################
    "${SPath}/vbm_pipeline_start.pl" "$@"
else

    ## It is recommended to setup NOTIFICATION_EMAIL set in env, bashrc, or bashrc_for_SAMBA
    if [[ "x${NOTIFICATION_EMAIL}x" == "xx" ]]; then
        email="${USER}@duke.edu";
    else
        email=${NOTIFICATION_EMAIL};
    fi

    kill_cmd='';
    sb_dir=${HOME}/SAMBA_sbatch;
    if [[ ! -d ${sb_dir} ]]; then
        mkdir -m 775 ${sb_dir};
    fi

    date_tag=$(date --rfc-3339=seconds | tr ' ' '_' | tr ':' '.' | tr -d '-');
    name="SAMBA_pipeline_${date_tag}";
    sbatch_file="${sb_dir}/${name}.bash";
    outfix="${sb_dir}/slurm-";

    echo '#! /bin/env bash' > "${sbatch_file}"

    if [[ ${cluster_code} == 1 ]]; then
        #######################################################################
        # Slurm
        #######################################################################
        echo "#SBATCH  --mem=8000" >> "${sbatch_file}";
        echo "#SBATCH  -v" >> "${sbatch_file}";
        echo "#SBATCH  -s" >> "${sbatch_file}";
        echo "#SBATCH --mail-user=${email}" >> "${sbatch_file}";
        echo "#SBATCH --mail-type=END,FAIL" >> "${sbatch_file}";
        echo "#SBATCH --output=${outfix}%j.out" >> "${sbatch_file}";
        echo "#SBATCH --error=${outfix}%j.out" >> "${sbatch_file}";
        echo "#SBATCH --job-name=${name}" >> "${sbatch_file}";

        # IMPORTANT: On the worker node, run the pipeline via container
        # if CONTAINER_CMD_PREFIX was set; otherwise, bare pipeline.
        echo "${PIPELINE_LAUNCH} $@" >> "${sbatch_file}";

        cmd="sbatch ${sbatch_file}";

        echo "${cmd}";
        echo " ";
        echo " ";

        job_id=$(${cmd} | cut -d ' ' -f 4);
        kill_cmd="scancel ${job_id}"

    elif [[ ${cluster_code} == 2 ]]; then
        #######################################################################
        # SGE
        #######################################################################
        echo "#\$ -N ${name}" >> "${sbatch_file}";
        echo "#\$ -M ${USER}@duke.edu" >> "${sbatch_file}";
        echo "#\$ -m ea" >> "${sbatch_file}";
        echo "#\$ -o ${outfix}"'$JOB_ID.out' >> "${sbatch_file}";
        echo "#\$ -e ${outfix}"'$JOB_ID.out' >> "${sbatch_file}";
        echo "#\$ -l h_vmem=8000M,vf=8000M" >> "${sbatch_file}";

        # Same idea for SGE worker nodes.
        echo "${PIPELINE_LAUNCH} $@" >> "${sbatch_file}";

        # 9 January 2020 (Thurs): '-b y' was not the right thing to do here, and is why $JOB_ID, etc no workey
        # 27 February 2020 BJA: For BIAC cluster, want to run on long queue to avoid premature job deletion.
        # q_string can be hardcoded by the user
        q_string='';
        host=${HOSTNAME};
        host_test=$(echo "$host" | sed 's/blade[0-9]*.dhe.duke.edu//g');
        if [[ "x${host_test}x" == "xx" ]]; then
            q_string="-q long.q ";
        fi
        cmd="qsub ${q_string}-terse -V ${sbatch_file}";
        echo "${cmd}";
        echo " ";
        echo " ";
        job_id=$(${cmd} | tail -1);
        kill_cmd="qdel ${job_id}"
    fi

    echo "JOB ID = ${job_id}";
    echo "";

    pb_test=$(which pbcopy 2>&1 | grep 'no pbcopy in' | wc -l);
    if ( [[ "x${pb_test}x" == 'x0x' ]] ); then
        echo "To stop this instance of SAMBA pipeline please use the following command, and will be automatically copied to your clipboard :";
        pbcopy < <(printf '%s\n' "${kill_cmd}");
    else
        echo "To stop this instance of SAMBA pipeline please use the following command:";
        echo "${kill_cmd}";
    fi
    sleep 3;

    sb_file="${sb_dir}/slurm-${job_id}.out";
    # Make sure it exists so we can immediately call the tail command without risk of erroring out.
    touch "${sb_file}";
    tail -f "${sb_file}";
fi

exit 0;
